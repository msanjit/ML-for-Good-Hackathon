{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d1008c",
   "metadata": {},
   "source": [
    "# ML-for-Good-Hackathon\n",
    "# Team Name: Vcare\n",
    "# Participants: Sanjit Mehta, Naveena Chandwani, Rohith Rathod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c71baa",
   "metadata": {},
   "source": [
    "### Import Common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc08c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914208a0",
   "metadata": {},
   "source": [
    "### Import NLP related packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259abc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install contractions\n",
    "import contractions\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "#pip install gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af62a5",
   "metadata": {},
   "source": [
    "### Import Data and Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678d49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    path = 'C:/Users/NLP/data/' # use your path\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "    # Drop duplicates\n",
    "    cols_req = [\"focus_group_subtype\", \"focus_group_subtype_id\", \"doc_no_within_subtype\", \"question_id\", \n",
    "                \"question_text\", \"parent_num\", \"parent_answer\"]\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df[cols_req]\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a681d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focus_group_subtype</th>\n",
       "      <th>focus_group_subtype_id</th>\n",
       "      <th>doc_no_within_subtype</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>parent_num</th>\n",
       "      <th>parent_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sure. Hi. My name is Parent 5. I have three ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi everyone. My name is Parent 1, I have two b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>3</td>\n",
       "      <td>Hi everybody. My name is Parent 3 and I have a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>4</td>\n",
       "      <td>Hi, I'm Parent 4, I have a 15-year-old daughte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>2</td>\n",
       "      <td>Oh, I'm sorry. I lost connection, I couldn't h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  focus_group_subtype  focus_group_subtype_id  doc_no_within_subtype  \\\n",
       "0        gaming_group                       1                      1   \n",
       "1        gaming_group                       1                      1   \n",
       "2        gaming_group                       1                      1   \n",
       "3        gaming_group                       1                      1   \n",
       "4        gaming_group                       1                      1   \n",
       "\n",
       "   question_id                                      question_text  parent_num  \\\n",
       "0            1  So, I was thinking we could start by just goin...           5   \n",
       "1            1  So, I was thinking we could start by just goin...           1   \n",
       "2            1  So, I was thinking we could start by just goin...           3   \n",
       "3            1  So, I was thinking we could start by just goin...           4   \n",
       "4            1  So, I was thinking we could start by just goin...           2   \n",
       "\n",
       "                                       parent_answer  \n",
       "0  Sure. Hi. My name is Parent 5. I have three ki...  \n",
       "1  Hi everyone. My name is Parent 1, I have two b...  \n",
       "2  Hi everybody. My name is Parent 3 and I have a...  \n",
       "3  Hi, I'm Parent 4, I have a 15-year-old daughte...  \n",
       "4  Oh, I'm sorry. I lost connection, I couldn't h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = read_data()\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b1d9e",
   "metadata": {},
   "source": [
    "# Preprocessing of text Data\n",
    "1. Expand contraction\n",
    "2. Case handling\n",
    "3. Remove punctuations\n",
    "4. Remove words and digits containing digits\n",
    "5. Remove stop word\n",
    "6. Lemmatization\n",
    "7. Remove Extra Spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38ef70",
   "metadata": {},
   "source": [
    "#### 1. Expand contraction\n",
    "Contraction is the shortened form of a word like don’t stands for do not, aren’t stands for are not. Like this, we need to expand this contraction in the text data for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215efe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contraction(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text:contractions.fix(text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f4738",
   "metadata": {},
   "source": [
    "#### 2. Case handling\n",
    "If the text is in the same case, it is easy for a machine to interpret the words because the lower case and upper case are treated differently by the machine. for example, words like Ball and ball are treated differently by machine. So, we need to make the text in the same case and the most preferred case is a lower case to avoid such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e100e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_handling(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower() \n",
    "        \n",
    "    return df       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527044f",
   "metadata": {},
   "source": [
    "#### 3. Remove punctuations\n",
    "One of the other text processing techniques is removing punctuations. there are total 32 main punctuations that need to be taken care of. we can directly use the string module with a regular expression to replace any punctuation in text with an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0171de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub('[%s]' % re.escape(string.punctuation), '' , text))\n",
    "        df[col] = df[col].apply(lambda text: text.replace(\"_\",\" \"))\n",
    "        \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc5a36",
   "metadata": {},
   "source": [
    "#### 4. Remove words and digits containing digits\n",
    "Sometimes it happens that words and digits combine are written in the text which creates a problem for machines to understand. hence, We need to remove the words and digits which are combined like game57 or game5ts7. This type of word is difficult to process so better to remove them or replace them with an empty string. we use regular expressions for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ebeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words_dgits(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub(\" \\d+\",'',text))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa4247",
   "metadata": {},
   "source": [
    "#### 5. Remove stopword\n",
    "Stopwords are the most commonly occurring words in a text which do not provide any valuable information. stopwords like they, there, this, where, etc are some of the stopwords. NLTK library is a common library that is used to remove stopwords and include approximately 180 stopwords which it removes. If we want to add any new word to a set of words then it is easy using the add method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2fb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df, columns=[]):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def remove_sw(text):\n",
    "        txt_output = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "        return txt_output\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: remove_sw(text))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb660f89",
   "metadata": {},
   "source": [
    "#### 6. Lemmatization\n",
    "Lemmatization is similar to stemming, used to stem the words into root word but differs in working. Actually, Lemmatization is a systematic way to reduce the words into their lemma by matching them with a language dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b57de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(df, columns=[]):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(text):\n",
    "        text_output = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "        return text_output\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: lemmatize(text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d922d",
   "metadata": {},
   "source": [
    "#### 7. Remove Extra Spaces \n",
    "Most of the time text data contain extra spaces or while performing the above preprocessing techniques more than one space is left between the text so we need to control this problem. regular expression library performs well to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86e6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub(' +', ' ', text))\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ea0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df, columns=[]):\n",
    "    \n",
    "    df = expand_contraction(df,columns)\n",
    "    df = case_handling(df,columns) \n",
    "    df = remove_punctuations(df,columns)\n",
    "    df = remove_words_dgits(df,columns)  \n",
    "    df = remove_stopwords(df,columns) \n",
    "    df = lemmatize_words(df, columns)\n",
    "    df = remove_extra_spaces(df,columns) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f2c5b",
   "metadata": {},
   "source": [
    "## Data preprocessing function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ebf681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focus_group_subtype</th>\n",
       "      <th>focus_group_subtype_id</th>\n",
       "      <th>doc_no_within_subtype</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>parent_num</th>\n",
       "      <th>parent_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>5</td>\n",
       "      <td>sure hi name parent three kid nine boy good sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi everyone name parent two boy ayearold almos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>3</td>\n",
       "      <td>hi everybody name parent anyearold daughter an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>4</td>\n",
       "      <td>hi parent ayearold daughter ayearold son one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>2</td>\n",
       "      <td>oh sorry lost connection could hear anyone nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So, I was thinking we could start by just goin...</td>\n",
       "      <td>2</td>\n",
       "      <td>crosstalk series yes myyearolds love certain t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>We thought that a good way to start might be i...</td>\n",
       "      <td>2</td>\n",
       "      <td>oh okay well use much mean teacher would assig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>We thought that a good way to start might be i...</td>\n",
       "      <td>3</td>\n",
       "      <td>would say thing daughter fifth grade would cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>We thought that a good way to start might be i...</td>\n",
       "      <td>5</td>\n",
       "      <td>similar experience parent high schooler lot ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gaming_group</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>We thought that a good way to start might be i...</td>\n",
       "      <td>5</td>\n",
       "      <td>weekend hour something like much youtube watch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  focus_group_subtype  focus_group_subtype_id  doc_no_within_subtype  \\\n",
       "0        gaming_group                       1                      1   \n",
       "1        gaming_group                       1                      1   \n",
       "2        gaming_group                       1                      1   \n",
       "3        gaming_group                       1                      1   \n",
       "4        gaming_group                       1                      1   \n",
       "5        gaming_group                       1                      1   \n",
       "6        gaming_group                       1                      1   \n",
       "7        gaming_group                       1                      1   \n",
       "8        gaming_group                       1                      1   \n",
       "9        gaming_group                       1                      1   \n",
       "\n",
       "   question_id                                      question_text  parent_num  \\\n",
       "0            1  So, I was thinking we could start by just goin...           5   \n",
       "1            1  So, I was thinking we could start by just goin...           1   \n",
       "2            1  So, I was thinking we could start by just goin...           3   \n",
       "3            1  So, I was thinking we could start by just goin...           4   \n",
       "4            1  So, I was thinking we could start by just goin...           2   \n",
       "5            1  So, I was thinking we could start by just goin...           2   \n",
       "6            2  We thought that a good way to start might be i...           2   \n",
       "7            2  We thought that a good way to start might be i...           3   \n",
       "8            2  We thought that a good way to start might be i...           5   \n",
       "9            2  We thought that a good way to start might be i...           5   \n",
       "\n",
       "                                       parent_answer  \n",
       "0  sure hi name parent three kid nine boy good sh...  \n",
       "1  hi everyone name parent two boy ayearold almos...  \n",
       "2  hi everybody name parent anyearold daughter an...  \n",
       "3  hi parent ayearold daughter ayearold son one s...  \n",
       "4  oh sorry lost connection could hear anyone nam...  \n",
       "5  crosstalk series yes myyearolds love certain t...  \n",
       "6  oh okay well use much mean teacher would assig...  \n",
       "7  would say thing daughter fifth grade would cou...  \n",
       "8  similar experience parent high schooler lot ho...  \n",
       "9  weekend hour something like much youtube watch...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "columns=['parent_answer']\n",
    "output_df =  data_preprocessing(input_df, columns)\n",
    "output_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
