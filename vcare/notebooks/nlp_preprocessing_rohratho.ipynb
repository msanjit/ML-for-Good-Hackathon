{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d1008c",
   "metadata": {},
   "source": [
    "# NLP Notes:\n",
    "Natural Language Processing is a branch of Artificial Intelligence that analyzes, processes, and efficiently retrieves information text data. By utilizing the power of NLP one can solve a huge range of real-world problems which include summarizing documents, title generator, caption generator, fraud detection, speech recognition, recommendation system, machine translation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c71baa",
   "metadata": {},
   "source": [
    "## Import Common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc08c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914208a0",
   "metadata": {},
   "source": [
    "## Import NLP related packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259abc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install contractions\n",
    "import contractions\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af62a5",
   "metadata": {},
   "source": [
    "## Import Data and Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678d49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/NLP/data/media_group.csv')\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74dc65cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focus_group_subtype</th>\n",
       "      <th>focus_group_subtype_id</th>\n",
       "      <th>doc_no_within_subtype</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>parent_num</th>\n",
       "      <th>parent_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>5</td>\n",
       "      <td>My son goes to our charter school. Before the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>1</td>\n",
       "      <td>It was pretty minimal for school. It was mostl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>4</td>\n",
       "      <td>My child also had access to the computer befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>3</td>\n",
       "      <td>My son before the pandemic was mostly iPad for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>2</td>\n",
       "      <td>My son's older through all these kids, but he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>1</td>\n",
       "      <td>I don't know. It's been ... I mean, because sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>how did your child use technology before the p...</td>\n",
       "      <td>6</td>\n",
       "      <td>Okay. I have an 11-year-old boy who is in sixt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>what do you anticipate as people return to in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Okay. Real quick. Both my kids, my son is ADHD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>what do you anticipate as people return to in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The return to school, I mean, right now, she's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>what do you anticipate as people return to in ...</td>\n",
       "      <td>4</td>\n",
       "      <td>I would say my son's school is not going back ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  focus_group_subtype  focus_group_subtype_id  doc_no_within_subtype  \\\n",
       "0         media_group                       3                      1   \n",
       "1         media_group                       3                      1   \n",
       "2         media_group                       3                      1   \n",
       "3         media_group                       3                      1   \n",
       "4         media_group                       3                      1   \n",
       "5         media_group                       3                      1   \n",
       "6         media_group                       3                      1   \n",
       "7         media_group                       3                      1   \n",
       "8         media_group                       3                      1   \n",
       "9         media_group                       3                      1   \n",
       "\n",
       "   question_id                                      question_text  parent_num  \\\n",
       "0            2  how did your child use technology before the p...           5   \n",
       "1            2  how did your child use technology before the p...           1   \n",
       "2            2  how did your child use technology before the p...           4   \n",
       "3            2  how did your child use technology before the p...           3   \n",
       "4            2  how did your child use technology before the p...           2   \n",
       "5            2  how did your child use technology before the p...           1   \n",
       "6            2  how did your child use technology before the p...           6   \n",
       "7            3  what do you anticipate as people return to in ...           3   \n",
       "8            3  what do you anticipate as people return to in ...           1   \n",
       "9            3  what do you anticipate as people return to in ...           4   \n",
       "\n",
       "                                       parent_answer  \n",
       "0  My son goes to our charter school. Before the ...  \n",
       "1  It was pretty minimal for school. It was mostl...  \n",
       "2  My child also had access to the computer befor...  \n",
       "3  My son before the pandemic was mostly iPad for...  \n",
       "4  My son's older through all these kids, but he'...  \n",
       "5  I don't know. It's been ... I mean, because sh...  \n",
       "6  Okay. I have an 11-year-old boy who is in sixt...  \n",
       "7  Okay. Real quick. Both my kids, my son is ADHD...  \n",
       "8  The return to school, I mean, right now, she's...  \n",
       "9  I would say my son's school is not going back ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b1d9e",
   "metadata": {},
   "source": [
    "# Preprocessing of text Data\n",
    "1. Expand contraction\n",
    "2. Case handling\n",
    "3. Remove punctuations\n",
    "4. Remove words and digits containing digits\n",
    "5. Remove stop word\n",
    "6. Lemmatization\n",
    "7. Remove Extra Spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38ef70",
   "metadata": {},
   "source": [
    "#### 1. Expand contraction\n",
    "Contraction is the shortened form of a word like don’t stands for do not, aren’t stands for are not. Like this, we need to expand this contraction in the text data for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215efe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contraction(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text:contractions.fix(text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f4738",
   "metadata": {},
   "source": [
    "#### 2. Case handling\n",
    "If the text is in the same case, it is easy for a machine to interpret the words because the lower case and upper case are treated differently by the machine. for example, words like Ball and ball are treated differently by machine. So, we need to make the text in the same case and the most preferred case is a lower case to avoid such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e100e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_handling(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower() \n",
    "        \n",
    "    return df       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527044f",
   "metadata": {},
   "source": [
    "#### 3. Remove punctuations\n",
    "One of the other text processing techniques is removing punctuations. there are total 32 main punctuations that need to be taken care of. we can directly use the string module with a regular expression to replace any punctuation in text with an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0171de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub('[%s]' % re.escape(string.punctuation), '' , text))\n",
    "        \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc5a36",
   "metadata": {},
   "source": [
    "#### 4. Remove words and digits containing digits\n",
    "Sometimes it happens that words and digits combine are written in the text which creates a problem for machines to understand. hence, We need to remove the words and digits which are combined like game57 or game5ts7. This type of word is difficult to process so better to remove them or replace them with an empty string. we use regular expressions for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ebeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words_dgits(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub('W*dw*','',text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa4247",
   "metadata": {},
   "source": [
    "#### 5. Remove stopword\n",
    "Stopwords are the most commonly occurring words in a text which do not provide any valuable information. stopwords like they, there, this, where, etc are some of the stopwords. NLTK library is a common library that is used to remove stopwords and include approximately 180 stopwords which it removes. If we want to add any new word to a set of words then it is easy using the add method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2fb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df, columns=[]):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def remove_sw(text):\n",
    "        txt_output = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "        return txt_output\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: remove_sw(text))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb660f89",
   "metadata": {},
   "source": [
    "#### 6. Lemmatization\n",
    "Lemmatization is similar to stemming, used to stem the words into root word but differs in working. Actually, Lemmatization is a systematic way to reduce the words into their lemma by matching them with a language dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b57de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(df, columns=[]):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(text):\n",
    "        text_output = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "        return text_output\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: lemmatize(text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d922d",
   "metadata": {},
   "source": [
    "#### 7. Remove Extra Spaces \n",
    "Most of the time text data contain extra spaces or while performing the above preprocessing techniques more than one space is left between the text so we need to control this problem. regular expression library performs well to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86e6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(df,columns=[]):\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda text: re.sub(' +', ' ', text))\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f2c5b",
   "metadata": {},
   "source": [
    "# Data preprocessing entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ea0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df, columns=[]):\n",
    "    \n",
    "    df = expand_contraction(df,columns)\n",
    "    df = case_handling(df,columns) \n",
    "    df = remove_punctuations(df,columns)\n",
    "    #df = remove_words_dgits(df,columns)  \n",
    "    df = remove_stopwords(df,columns) \n",
    "    df = lemmatize_words(df, columns)\n",
    "    df = remove_extra_spaces(df,columns) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ebf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['parent_answer', 'question_text']\n",
    "output_df =  data_preprocessing(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9bc8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focus_group_subtype</th>\n",
       "      <th>focus_group_subtype_id</th>\n",
       "      <th>doc_no_within_subtype</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>parent_num</th>\n",
       "      <th>parent_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>5</td>\n",
       "      <td>son go charter school pandemic using computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>1</td>\n",
       "      <td>pretty minimal school mostly mean use chromebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>4</td>\n",
       "      <td>child also access computer pandemic school als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>3</td>\n",
       "      <td>son pandemic mostly ipad accommodation would u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>2</td>\n",
       "      <td>son older kid still trying get diploma high sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>1</td>\n",
       "      <td>know mean remote certain time mean horribleit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>6</td>\n",
       "      <td>okay 11yearold boy sixth grade sevenyearold gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>anticipate people return person concern anythi...</td>\n",
       "      <td>3</td>\n",
       "      <td>okay real quick kid son adhd asd daughter adhd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>anticipate people return person concern anythi...</td>\n",
       "      <td>1</td>\n",
       "      <td>return school mean right three day one week tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>anticipate people return person concern anythi...</td>\n",
       "      <td>4</td>\n",
       "      <td>would say son school going back session going ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  focus_group_subtype  focus_group_subtype_id  doc_no_within_subtype  \\\n",
       "0         media_group                       3                      1   \n",
       "1         media_group                       3                      1   \n",
       "2         media_group                       3                      1   \n",
       "3         media_group                       3                      1   \n",
       "4         media_group                       3                      1   \n",
       "5         media_group                       3                      1   \n",
       "6         media_group                       3                      1   \n",
       "7         media_group                       3                      1   \n",
       "8         media_group                       3                      1   \n",
       "9         media_group                       3                      1   \n",
       "\n",
       "   question_id                                      question_text  parent_num  \\\n",
       "0            2  child use technology pandemic educational purpose           5   \n",
       "1            2  child use technology pandemic educational purpose           1   \n",
       "2            2  child use technology pandemic educational purpose           4   \n",
       "3            2  child use technology pandemic educational purpose           3   \n",
       "4            2  child use technology pandemic educational purpose           2   \n",
       "5            2  child use technology pandemic educational purpose           1   \n",
       "6            2  child use technology pandemic educational purpose           6   \n",
       "7            3  anticipate people return person concern anythi...           3   \n",
       "8            3  anticipate people return person concern anythi...           1   \n",
       "9            3  anticipate people return person concern anythi...           4   \n",
       "\n",
       "                                       parent_answer  \n",
       "0  son go charter school pandemic using computer ...  \n",
       "1  pretty minimal school mostly mean use chromebo...  \n",
       "2  child also access computer pandemic school als...  \n",
       "3  son pandemic mostly ipad accommodation would u...  \n",
       "4  son older kid still trying get diploma high sc...  \n",
       "5  know mean remote certain time mean horribleit ...  \n",
       "6  okay 11yearold boy sixth grade sevenyearold gi...  \n",
       "7  okay real quick kid son adhd asd daughter adhd...  \n",
       "8  return school mean right three day one week tw...  \n",
       "9  would say son school going back session going ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68741909",
   "metadata": {},
   "source": [
    "# TD-IDF Vectorizer VS TD-IDF Transformer\n",
    "TF-IDF is a score which is applied to every word in every document in our dataset. And for every word, the TF-IDF value increases with every appearance of the word in a document, but is gradually decreased with every appearance in other documents. \n",
    "\n",
    "Theoretically speaking, there is actually no difference between the 2 implementations. Practically speaking, we need to write some more code if we want to use TfidfTransformer. The main difference between the 2 implementations is that TfidfVectorizer performs both term frequency and inverse document frequency for you, while using TfidfTransformer will require you to use the CountVectorizer class from Scikit-Learn to perform Term Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20055111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5a9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = output_df['parent_answer'].tolist()\n",
    "tdidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tdidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_df = pd.DataFrame(tfIdf[0].T.todense(), index=tdidf_vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "tfidf_df = tfidf_df.sort_values(\"TF-IDF\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c40a5e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>understood</th>\n",
       "      <td>0.370622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>0.282573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>0.259517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.238669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>0.190190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framework</th>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>britannica</th>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search</th>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beneficial</th>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encyclopedia</th>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TF-IDF\n",
       "understood    0.370622\n",
       "book          0.282573\n",
       "access        0.259517\n",
       "able          0.238669\n",
       "always        0.190190\n",
       "framework     0.185311\n",
       "britannica    0.185311\n",
       "search        0.185311\n",
       "beneficial    0.185311\n",
       "encyclopedia  0.185311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5a3db",
   "metadata": {},
   "source": [
    "# Unsupervised Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a950ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "#pip install gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dec28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['parent_answer'] =  output_df['parent_answer'].apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eebc046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row for row in output_df.parent_answer]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9080ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     #size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efa3fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.01 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-9cdc5012bacd>:7: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9be9ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "314e1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export = output_df.copy()\n",
    "file_export['old_parent_answer'] = file_export.parent_answer\n",
    "file_export.old_parent_answer = file_export.old_parent_answer.str.join(' ')\n",
    "file_export.parent_answer = file_export.parent_answer.apply(lambda x: ' '.join(bigram[x]))\n",
    "#file_export.rate = file_export.rate.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0d8fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export[['parent_answer']].to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326a0816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focus_group_subtype</th>\n",
       "      <th>focus_group_subtype_id</th>\n",
       "      <th>doc_no_within_subtype</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>parent_num</th>\n",
       "      <th>parent_answer</th>\n",
       "      <th>old_parent_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>5</td>\n",
       "      <td>son go_charter school pandemic using_computer ...</td>\n",
       "      <td>son go charter school pandemic using computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>1</td>\n",
       "      <td>pretty minimal school mostly mean use chromebo...</td>\n",
       "      <td>pretty minimal school mostly mean use chromebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>4</td>\n",
       "      <td>child also access computer pandemic school als...</td>\n",
       "      <td>child also access computer pandemic school als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>3</td>\n",
       "      <td>son pandemic mostly ipad accommodation would u...</td>\n",
       "      <td>son pandemic mostly ipad accommodation would u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media_group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>child use technology pandemic educational purpose</td>\n",
       "      <td>2</td>\n",
       "      <td>son_older kid still trying_get diploma high_sc...</td>\n",
       "      <td>son older kid still trying get diploma high sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  focus_group_subtype  focus_group_subtype_id  doc_no_within_subtype  \\\n",
       "0         media_group                       3                      1   \n",
       "1         media_group                       3                      1   \n",
       "2         media_group                       3                      1   \n",
       "3         media_group                       3                      1   \n",
       "4         media_group                       3                      1   \n",
       "\n",
       "   question_id                                      question_text  parent_num  \\\n",
       "0            2  child use technology pandemic educational purpose           5   \n",
       "1            2  child use technology pandemic educational purpose           1   \n",
       "2            2  child use technology pandemic educational purpose           4   \n",
       "3            2  child use technology pandemic educational purpose           3   \n",
       "4            2  child use technology pandemic educational purpose           2   \n",
       "\n",
       "                                       parent_answer  \\\n",
       "0  son go_charter school pandemic using_computer ...   \n",
       "1  pretty minimal school mostly mean use chromebo...   \n",
       "2  child also access computer pandemic school als...   \n",
       "3  son pandemic mostly ipad accommodation would u...   \n",
       "4  son_older kid still trying_get diploma high_sc...   \n",
       "\n",
       "                                   old_parent_answer  \n",
       "0  son go charter school pandemic using computer ...  \n",
       "1  pretty minimal school mostly mean use chromebo...  \n",
       "2  child also access computer pandemic school als...  \n",
       "3  son pandemic mostly ipad accommodation would u...  \n",
       "4  son older kid still trying get diploma high sc...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91506f06",
   "metadata": {},
   "source": [
    "# KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad37afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77b49153",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc7c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4358f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 0.9999430179595947),\n",
       " ('going', 0.9999169111251831),\n",
       " ('thing', 0.9999097585678101),\n",
       " ('lot', 0.9999040365219116),\n",
       " ('kid', 0.999903678894043),\n",
       " ('day', 0.9999033808708191),\n",
       " ('class', 0.9998947978019714),\n",
       " ('something', 0.9998836517333984),\n",
       " ('time', 0.9998831748962402),\n",
       " ('really', 0.9998794794082642)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cc36bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "101537b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e22ba28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2e9e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>[-0.087506786, 0.06588098, 0.08399521, 0.04410...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93.324066</td>\n",
       "      <td>93.324066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thing</td>\n",
       "      <td>[-0.089280754, 0.06674363, 0.084365815, 0.0435...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.336956</td>\n",
       "      <td>74.336956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school</td>\n",
       "      <td>[-0.08718752, 0.06679961, 0.08080908, 0.041982...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59.851661</td>\n",
       "      <td>59.851661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>going</td>\n",
       "      <td>[-0.089307986, 0.06810554, 0.083315134, 0.0419...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.387419</td>\n",
       "      <td>77.387419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kid</td>\n",
       "      <td>[-0.08896042, 0.06643233, 0.081441745, 0.04171...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.990519</td>\n",
       "      <td>71.990519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>know</td>\n",
       "      <td>[-0.08963193, 0.06641954, 0.08263298, 0.039908...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61.301438</td>\n",
       "      <td>61.301438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>really</td>\n",
       "      <td>[-0.084751, 0.06429121, 0.082660295, 0.0423803...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64.353029</td>\n",
       "      <td>64.353029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>go</td>\n",
       "      <td>[-0.08496199, 0.0647335, 0.08556023, 0.0445570...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.249215</td>\n",
       "      <td>62.249215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>time</td>\n",
       "      <td>[-0.09002568, 0.06858209, 0.08407999, 0.044753...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.319950</td>\n",
       "      <td>65.319950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>think</td>\n",
       "      <td>[-0.08879573, 0.06407977, 0.080693446, 0.04480...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.305008</td>\n",
       "      <td>62.305008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words                                            vectors  cluster  \\\n",
       "0    like  [-0.087506786, 0.06588098, 0.08399521, 0.04410...        1   \n",
       "1   thing  [-0.089280754, 0.06674363, 0.084365815, 0.0435...        1   \n",
       "2  school  [-0.08718752, 0.06679961, 0.08080908, 0.041982...        1   \n",
       "3   going  [-0.089307986, 0.06810554, 0.083315134, 0.0419...        1   \n",
       "4     kid  [-0.08896042, 0.06643233, 0.081441745, 0.04171...        1   \n",
       "5    know  [-0.08963193, 0.06641954, 0.08263298, 0.039908...        1   \n",
       "6  really  [-0.084751, 0.06429121, 0.082660295, 0.0423803...        1   \n",
       "7      go  [-0.08496199, 0.0647335, 0.08556023, 0.0445570...        1   \n",
       "8    time  [-0.09002568, 0.06858209, 0.08407999, 0.044753...        1   \n",
       "9   think  [-0.08879573, 0.06407977, 0.080693446, 0.04480...        1   \n",
       "\n",
       "   cluster_value  closeness_score  sentiment_coeff  \n",
       "0              1        93.324066        93.324066  \n",
       "1              1        74.336956        74.336956  \n",
       "2              1        59.851661        59.851661  \n",
       "3              1        77.387419        77.387419  \n",
       "4              1        71.990519        71.990519  \n",
       "5              1        61.301438        61.301438  \n",
       "6              1        64.353029        64.353029  \n",
       "7              1        62.249215        62.249215  \n",
       "8              1        65.319950        65.319950  \n",
       "9              1        62.305008        62.305008  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d96320de",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5823b",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87061a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9cf4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c916b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4dd7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = final_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb04fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.parent_answer)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.parent_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa762cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.parent_answer.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a51f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\n",
    "#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b26b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61a648bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.parent_answer.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9efe3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.parent_answer]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'parent_answer']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc3b07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)  # or 1000\n",
    "# pd.set_option('display.max_rows', None)  # or 1000\n",
    "# pd.set_option('display.max_colwidth', -1)  # or 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46136793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>parent_answer</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[51.16967823000269, 12.150041364467253, 59.851...</td>\n",
       "      <td>[2.2264456601779945, 3.70805020110221, 2.97769...</td>\n",
       "      <td>son go_charter school pandemic using_computer ...</td>\n",
       "      <td>5442.709665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25.651072669700238, 11.05353918420877, 59.851...</td>\n",
       "      <td>[3.5257286443082556, 8.437751649736402, 4.4665...</td>\n",
       "      <td>pretty minimal school mostly mean use chromebo...</td>\n",
       "      <td>3627.236638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[38.258617769129565, 51.08810571118995, 35.694...</td>\n",
       "      <td>[2.83258146374831, 10.909969488035802, 6.47609...</td>\n",
       "      <td>child also access computer pandemic school als...</td>\n",
       "      <td>13693.814362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[51.16967823000269, 29.082246264894614, 19.889...</td>\n",
       "      <td>[2.2264456601779945, 4.545931351625775, 3.3715...</td>\n",
       "      <td>son pandemic mostly ipad accommodation would u...</td>\n",
       "      <td>9949.746402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 71.99051860639777, 47.754613623606055, 24....</td>\n",
       "      <td>[4.218875824868201, 3.2078320936640052, 2.1819...</td>\n",
       "      <td>son_older kid still trying_get diploma high_sc...</td>\n",
       "      <td>11418.018840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[61.30143787442263, 56.63963855498419, 0, 65.3...</td>\n",
       "      <td>[1.556287997842748, 5.955850810083319, 4.21887...</td>\n",
       "      <td>know mean remote_certain time mean_horribleit ...</td>\n",
       "      <td>4040.034258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[25.5662280334024, 27.615178486745155, 27.1838...</td>\n",
       "      <td>[3.0149030205422647, 3.70805020110221, 3.70805...</td>\n",
       "      <td>okay 11yearold boy sixth_grade sevenyearold gi...</td>\n",
       "      <td>34266.244464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[25.5662280334024, 16.73378992578032, 71.99051...</td>\n",
       "      <td>[3.0149030205422647, 3.9311937524164198, 3.207...</td>\n",
       "      <td>okay real_quick kid son_adhd asd daughter adhd...</td>\n",
       "      <td>19929.738922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 59.85166100302707, 56.63963855498419, 31.5...</td>\n",
       "      <td>[4.624340932976365, 13.399620453424939, 3.9705...</td>\n",
       "      <td>return school mean right three_day one week_tw...</td>\n",
       "      <td>32266.332149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[44.399703506099776, 51.16967823000269, 59.851...</td>\n",
       "      <td>[2.6094379124341005, 2.2264456601779945, 10.42...</td>\n",
       "      <td>would_say son school going_back session going ...</td>\n",
       "      <td>37961.217897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentiment_coeff  \\\n",
       "0  [51.16967823000269, 12.150041364467253, 59.851...   \n",
       "1  [25.651072669700238, 11.05353918420877, 59.851...   \n",
       "2  [38.258617769129565, 51.08810571118995, 35.694...   \n",
       "3  [51.16967823000269, 29.082246264894614, 19.889...   \n",
       "4  [0, 71.99051860639777, 47.754613623606055, 24....   \n",
       "5  [61.30143787442263, 56.63963855498419, 0, 65.3...   \n",
       "6  [25.5662280334024, 27.615178486745155, 27.1838...   \n",
       "7  [25.5662280334024, 16.73378992578032, 71.99051...   \n",
       "8  [0, 59.85166100302707, 56.63963855498419, 31.5...   \n",
       "9  [44.399703506099776, 51.16967823000269, 59.851...   \n",
       "\n",
       "                                        tfidf_scores  \\\n",
       "0  [2.2264456601779945, 3.70805020110221, 2.97769...   \n",
       "1  [3.5257286443082556, 8.437751649736402, 4.4665...   \n",
       "2  [2.83258146374831, 10.909969488035802, 6.47609...   \n",
       "3  [2.2264456601779945, 4.545931351625775, 3.3715...   \n",
       "4  [4.218875824868201, 3.2078320936640052, 2.1819...   \n",
       "5  [1.556287997842748, 5.955850810083319, 4.21887...   \n",
       "6  [3.0149030205422647, 3.70805020110221, 3.70805...   \n",
       "7  [3.0149030205422647, 3.9311937524164198, 3.207...   \n",
       "8  [4.624340932976365, 13.399620453424939, 3.9705...   \n",
       "9  [2.6094379124341005, 2.2264456601779945, 10.42...   \n",
       "\n",
       "                                       parent_answer  sentiment_rate  \\\n",
       "0  son go_charter school pandemic using_computer ...     5442.709665   \n",
       "1  pretty minimal school mostly mean use chromebo...     3627.236638   \n",
       "2  child also access computer pandemic school als...    13693.814362   \n",
       "3  son pandemic mostly ipad accommodation would u...     9949.746402   \n",
       "4  son_older kid still trying_get diploma high_sc...    11418.018840   \n",
       "5  know mean remote_certain time mean_horribleit ...     4040.034258   \n",
       "6  okay 11yearold boy sixth_grade sevenyearold gi...    34266.244464   \n",
       "7  okay real_quick kid son_adhd asd daughter adhd...    19929.738922   \n",
       "8  return school mean right three_day one week_tw...    32266.332149   \n",
       "9  would_say son school going_back session going ...    37961.217897   \n",
       "\n",
       "   prediction  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "5           1  \n",
       "6           1  \n",
       "7           1  \n",
       "8           1  \n",
       "9           1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = replacement_df\n",
    "final_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
